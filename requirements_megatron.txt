wandb>=0.16.2
flash-attn==2.4.2
transformers==4.37.1
tokenizers==0.15.1
datasets==2.16.1
accelerate==0.26.1
deepspeed==0.13.1
hydra-core>=1.3.2
git+https://github.com/facebookresearch/llama.git
sentencepiece >= 0.1.99
nltk >= 3.8.1
websockets >= 12.0
pydantic >= 2.5.3
peft==0.7.1
bitsandbytes==0.42.0
stanford-stk
h5py
open_clip_torch
megablocks